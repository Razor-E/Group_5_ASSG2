---
title: "Group 5 ASSG2"
output:
  pdf_document: default
  html_document: default
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,error = FALSE, message = FALSE,
                      warning = FALSE,
                      out.height = "\\textheight",  out.widtibh = "\\textwidth")
```

```{r packages, include=FALSE}
library(pagedown) # For simulating PDFs before knitting
library(dplyr)
library(psych) # For describe() providing summary stats
library(quantmod) # For importing stock from Yahoo
library(ggplot2) # Visualizations
library(forecast) # Autoplot
library(tseries) # ADF test and more
library(FinTS) # ARCH LM test
library(rugarch) # For ARCH(p) models
library(tibble)
library(scales) # For dates
```

**Importing Ford Motor Company stock statistics**

```{r importing, echo=TRUE}
#This code does it.
getSymbols('F', src = 'yahoo', from = as.Date('2022-01-01'), to = 
             as.Date('2025-03-20'))
```
**Some Ford's stock closing prices**

```{r closing prices, echo=FALSE}
F_closing <- F$F.Close
head(F_closing)
```
\newpage

**Time series plot of Ford's Closing prices**

```{r ts conversion, echo=FALSE}
F_closing_ts <- ts(F_closing, start = c(2022,1), frequency = 240)
autoplot(F_closing_ts) + ggtitle('Ford Company Stock closing prices')
```

-Ford Company's stock prices have been going down over the course of the 4 years. A sharp drop can be seen from the start of 2022 to the middle of the same year.

-Some seasonality can be seen from the middle of 2022 to the middle of 2023.

-We need to eliminate these components, so that the resulting time series can be easier to work with. Computing the log returns has the same effect as differencing the log of the time series. It can be shown that these returns exhibit stationarity from tests seen further below.

```{r daily log returns, echo=TRUE}
#This computes the daily log returns
F_returns <- diff(log(F_closing_ts))
```

*Some daily log returns*

```{r log returns, echo=FALSE}
tail(F_returns)
```


\newpage

**PART 1: EXPLORATORY DATA ANALYSIS**

**Log-returns ts plot**

```{r returns plot, echo=FALSE}
autoplot(F_returns) + 
  ggtitle('Ford Motor Stock daily log returns')
```


**Summary statistics of the returns**

```{r summary statistics, echo=FALSE}
describe(F_returns)
```

*Ford Company's stock returns have a mean of zero and a variance of 1. This can imply stationarity since these statistics do not change over time, but further tests are needed to truly confirm this.*

-Skewness measures asymmetry. This tells us whether there are extreme values on the left or on the right.

*The negative skewness of -1 suggests the returns have a slightly longer left tail. Large losses are therefore more likely to occur.*

-Kurtosis measures the tailedness of a distribution. This shows how often extreme values occur as compared to a normal distribution (Where kurtosis = 3).

*Results show that returns have a high kurtosis (returns are leptokurtic). Losses (or gains) occur more frequently than normal. This implies higher risk involved with this stock.*

\newpage

**ADF Stationarity test**

-Null hypothesis: The Series is non-stationary

*Fail to reject if P > [level of significance]*

-Alternative hypothesis: The Series is stationary

*Reject Null in favour of the alternative if P < [level of significance]*

-The results are as shown:

```{r adf, echo=FALSE}
print(adf.test(F_returns))
```

-Assuming the default significance level of 5% (0.05), The p-value shown is less than this. We therefore reject the null hypothesis in favour of the alternative one and conclude that Ford's returns are indeed stationary.

\newpage

**Checking for ARCH effects on squared returns**

```{r ARCH effects, echo=FALSE}
ggAcf(F_returns^2) + 
  ggtitle('Autocorrelations of Ford Company squared returns')
```

-Only 7 out of 480 lags exceed the confidence interval(~1.458% of lags). At 5% significance, 24 lags (480 * 5%) or more exceeding the confidence level would be regarded as statistically significant. We can therefore safely ignore all the lags appearing above the ci as there are statistically insignificant.

-The above plot therefore shows no significant autocorrelations seen from the squared returns; and therefore no volatility clustering. This means that volatility (squared returns) is homoscedastic (not heteroscedastic)... the variance, or volatility, is therefore constant. There are therefore no ARCH effects.

-ARCH effects can further be tested in depth using the Lagrange Multiplier (LM) test. 

\newpage

**ARCH-LM test**

-Null hypothesis: No ARCH effects (homoscedasticity)

-Alternative hypothesis: There is ARCH effects (heteroscedasticity)

*Reject Null hypothesis if P < [level of significance]*

```{r ARCH-LM, echo=FALSE}
print(ArchTest(F_returns))
```
-The p-value (0.9881) is significantly more than 0.05. We therefore fail to reject the Null hypothesis and conclude that Ford Company's stock returns are homoscedastic; they exhibit no ARCH effects.

\newpage

**PART 2 ARCH**

**Estimating ARCH(p)**

```{r modelling, echo=TRUE}
# Initialize vectors to store AIC values and models
aic_values <- numeric(5)
models <- list()

# Loop over p from 1 to 5 to find best ARCH(p)
for (p in 1:5) {
  # Define ARCH(p) spec as sGARCH(p, 0) with zero-mean
  spec <- ugarchspec(
    variance.model = list(model = "sGARCH", garchOrder = c(p, 0)),
    mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),  # Zero-mean model
    distribution.model = "norm"  # Normal distribution
  )
  
  # Fit the model to returns
  fit <- ugarchfit(spec = spec, data = F_returns)
  
  # Save AIC value
  aic_values[p] <- infocriteria(fit)[1]
  
  # Save model object
  models[[p]] <- fit
  
  # Print AIC for each p
  cat("ARCH(", p, ") AIC:", aic_values[p], "\n")
}
```

-The best model has the lowest AIC which is an ARCH(5) model as shown:

```{r lowest AIC, echo=FALSE}
# Find best p based on minimum AIC
best_p <- which.min(aic_values)
cat("\nBest ARCH(p): p =", best_p, "with AIC =", aic_values[best_p], "\n")
```
-The AIC indicates that 5 lags were optimal, suggesting that the conditional variance is influenced by the past five squared errors. A lower AIC value suggests a better model. 

-When the value of P was 5, the AIC had the lowest value.

\newpage

**Extract and plot the conditional volatility** 

```{r visualization}
best_model <- models[[best_p]]
conditional_volatility <- sigma(best_model)

num_obs <- length(conditional_volatility)

date_seq <- seq.Date(from = as.Date('2022-01-01'), 
                     to = as.Date('2025-03-20'), 
                     length.out = num_obs)

vol_data <- tibble(Time = date_seq, 
                   Volatility = conditional_volatility)

ggplot(vol_data, aes(x = Time, y = Volatility)) +
  geom_line() +
  labs(title = "Conditional Volatility Over Time",x = "Time",
       y = "Estimated Volatility") +
  scale_x_date(date_breaks = "3 months", date_labels = "%b %Y") +
  theme(plot.title = element_text(hjust = 0.5, size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

*The extreme spikes around August 2024, November 2023,and around October show sudden market shocks or major financial events.* 

-This means that there is higher risk involved for investors at this time. Traders of Ford's stock should have expected either a huge loss or a huge gain at this point in time.

-Higher volatility is disadvantageous to investors due to a high uncertainty involved in this stock. However, this could be great for traders who profit from volatility such as option traders.

-Some seasonality can be seen here. This proves that there is conditional heteroscedasticity or volatility clustering; Periods of low volatility following periods of high volatility.

\newpage

**Checking standardized residuals for autocorrelation**

```{r standardized}
# Extract standardized residuals
std_residuals <- residuals(best_model, standardize = TRUE)
```

-The Ljung Box test is used to check for this.

-Null hypothesis: No correlations are present in the data

*Fail to reject the Null hypothesis if P>[level of significance]*

-Results at alpha=0.05 are shown below

**Are there correlations in the residuals?**

```{r Ljung}
# Ljung-Box test for autocorrelation in standardized residuals
Box.test(std_residuals, lag = 10, type = "Ljung-Box")
```
-The p-value shown is significantly higher than 0.05. We therefore fail to reject the null hypothesis and conclude that the standardized residuals are purely white noise.

**Are there ARCH effects in the residuals?**

-Squaring the standard deviation of residuals gives us its variance which is similar to volatility.

-Testing whether the volatility of the residuals have any correlation also gives us the same result as shown below.

```{r Ljung arch}
# Ljung-Box test for squared standardized residuals (tests for remaining ARCH effects)
Box.test(std_residuals^2, lag = 10, type = "Ljung-Box")
```
-The p-value is higher than our 5% significance level and therefore, we fail to reject the null hypothesis. There is enough evidence to conclude that volatility of residuals have no correlations. There is therefore no remaining ARCH effects.

```{r Ljung plots}
# ACF plots
par(mfrow = c(1, 2))
ggAcf(std_residuals) + ggtitle("ACF of Std Residuals")
ggAcf(std_residuals^2) + ggtitle("ACF of Sq Std Residuals")
```

\newpage

**Discussion: Why ARCH(p) May Be Insufficient for Financial Volatility**

#Captures short-term volatility clustering poorly.

ARCH models require high orders (large p) to capture persistent volatility, which can lead to overfitting and inefficient estimation.

#Volatility persistence is not well-modeled.

Financial returns show long memory in volatility. ARCH models do not allow for volatility to decay slowly over time like GARCH models do.

#Cannot model asymmetry (leverage effect).

Financial markets often exhibit asymmetric volatility (negative shocks increase volatility more than positive shocks). ARCH ignores this.

#Residual diagnostics may show remaining ARCH effects.

Even after fitting ARCH, squared standardized residuals may still show autocorrelation, indicating that the model hasn't captured all dynamics.
**Part 4** 
**Asymmetric GJR-GARCH** 
#Fit a GJR-GARCH(1,1) model with a Student-t distribution (Include an AR(1) mean model). 

```{r}

library(rugarch)

# Use a smaller sample if needed
sample_returns <- tail(F_returns, 250)

# Specify the GJR-GARCH model
gjr_spec <- ugarchspec(
  variance.model = list(model = "gjrGARCH", garchOrder = c(1, 1)),
  mean.model = list(armaOrder = c(1, 0), include.mean = TRUE),
  distribution.model = "std"
)

# Fit the model
gjr_fit <- ugarchfit(spec = gjr_spec, data = sample_returns)

# Show the results
show(gjr_fit)

# Plot specific diagnostics to avoid freezing
par(mfrow = c(1, 1))
plot(gjr_fit, which = 1)  # Try different "which" numbers

```
#High p-values (greater than 0.05) mean no significant bias
#p-value is 0.7511 → You fail to reject the null hypothesis of no remaining asymmetry.


**Estimate the leverage parameter and test its significance**

```{r}
# View model results
show(gjr_fit)

# Extract coefficients table
coef_table <- gjr_fit@fit$matcoef
print(coef_table)


```
#Sign Bias test (p = 0.32): Not significant. No evidence that positive or negative shocks lead to different volatility responses.

#Negative Sign Bias test (p = 0.69): Not significant. Negative shocks don't disproportionately affect volatility.

#Positive Sign Bias test (p = 0.84): Not significant. Positive shocks don't disproportionately affect volatility.

#Joint Effect test (p = 0.75): Not significant. There's no joint evidence of asymmetry or leverage effects.

**Construct and plot the NIC for both GARCH(1,1) and GJR-GARCH(1,1) models, evaluating shocks 
from -10% to +10%. Comment on  the differences** 

```{r}
# =====================================
# 1. Fit GARCH(1,1) model with Student-t distribution
# =====================================
garch_spec <- ugarchspec(
  variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
  mean.model = list(armaOrder = c(1, 0), include.mean = TRUE),
  distribution.model = "std"
)

garch_fit <- ugarchfit(spec = garch_spec, data = F_returns)
show(garch_fit)

# =====================================
# 2. Fit GJR-GARCH(1,1) model with Student-t distribution
# =====================================
gjr_spec <- ugarchspec(
  variance.model = list(model = "gjrGARCH", garchOrder = c(1, 1)),
  mean.model = list(armaOrder = c(1, 0), include.mean = TRUE),
  distribution.model = "std"
)

gjr_fit <- ugarchfit(spec = gjr_spec, data = F_returns)
show(gjr_fit)

# =====================================
# 3. Extract coefficients
# =====================================
# GARCH(1,1)
garch_coef <- coef(garch_fit)
omega_g <- garch_coef["omega"]
alpha_g <- garch_coef["alpha1"]
beta_g  <- garch_coef["beta1"]

# GJR-GARCH(1,1)
gjr_coef <- coef(gjr_fit)
omega_j <- gjr_coef["omega"]
alpha_j <- gjr_coef["alpha1"]
gamma_j <- gjr_coef["gamma1"]
beta_j  <- gjr_coef["beta1"]

# =====================================
# 4. Construct and plot the NIC (News Impact Curve)
# =====================================
# Shock values from -10% to +10%
shocks <- seq(-0.10, 0.10, by = 0.001)

# Unconditional variances
unc_var_garch <- omega_g / (1 - alpha_g - beta_g)
unc_var_gjr <- omega_j / (1 - alpha_j - 0.5 * gamma_j - beta_j)

# NIC for GARCH(1,1)
nic_garch <- omega_g + alpha_g * shocks^2 + beta_g * unc_var_garch

# NIC for GJR-GARCH(1,1)
I_neg <- ifelse(shocks < 0, 1, 0)
nic_gjr <- omega_j + (alpha_j + gamma_j * I_neg) * shocks^2 + beta_j * unc_var_gjr

# Plot the NICs
plot(shocks, nic_garch, type = "l", col = "blue", lwd = 2, 
     ylab = "Conditional Variance", xlab = "Shock", 
     main = "News Impact Curve: GARCH(1,1) vs GJR-GARCH(1,1)")
lines(shocks, nic_gjr, col = "red", lwd = 2)
legend("topright", legend = c("GARCH(1,1)", "GJR-GARCH(1,1)"),
       col = c("blue", "red"), lwd = 2)

# =====================================
# 5. Leverage Effect Interpretation
# =====================================
# Leverage parameter is gamma_j
cat("Leverage Parameter (gamma1) for GJR-GARCH(1,1):", gamma_j, "\n")

# Test significance
summary(gjr_fit)
```
#blue curve is symmetric-It means that the model reacts equally to both positive and negative shocks.
Whether the shock is +5% or -5%, the increase in volatility is the same.
#GARCH(1,1) and GJR-GARCH(1,1) curves are very similar.
This suggests that Ford's stock returns don't show strong asymmetric volatility effects (at least in this sample period).
#both positive and negative shocks have similar impacts on volatility.

**Use the fitted GJR-GARCH(1,1) model to forecast volatility for the next 10 trading days, plot the 
forecasted volatility with confidence intervals.**

```{r}
# 4. Forecast Volatility for Next 10 Trading Days with GJR-GARCH(1,1)
# --------------------------
gjr_forecast <- ugarchforecast(gjr_fit, n.ahead = 10)

# Extract sigma (volatility forecasts)
sigma_forecast <- sigma(gjr_forecast)

# Plot forecasted volatility
forecast_days <- 1:10
plot(forecast_days, sigma_forecast, type = "o", col = "red", pch = 16,
     xlab = "Days Ahead", ylab = "Forecasted Volatility",
     main = "10-Day Volatility Forecast (GJR-GARCH(1,1))")

```
#The plot illustrates a downward trend in forecasted volatility, suggesting that the model predicts a decrease in market fluctuations over the specified period. The red dots likely represent the forecasted volatility values for each day, and while confidence intervals aren't explicitly shown, they would typically be represented as shaded areas or lines around the forecasted values, indicating the range of uncertainty in the predictions.


